# maya-system namespace
apiVersion: v1
kind: Namespace
metadata:
  name: maya-system


---

# maya-system-limit-range
apiVersion: v1
kind: LimitRange
metadata:
  name: maya-system-limit-range
  namespace: maya-system
  labels:
    mayadata.io/version: v1.11.1
spec:
  limits:
  - default:
      cpu: 1
      memory: 1Gi
    defaultRequest: 
      cpu: 50m
      memory: 50Mi
    type: Container


---

# maya-io service account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: maya-io
  namespace: maya-system

---

# maya-io cluster role binding
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: maya-io
  namespace: maya-system
subjects:
- kind: ServiceAccount
  name: maya-io
  namespace: maya-system
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io

---

# maya-credentials secret
apiVersion: v1
kind: Secret
metadata:
  name: maya-credentials-842dac64
  namespace: maya-system
type: Opaque
data:
  url: "aHR0cHM6Ly9kaXJlY3Rvci5tYXlhZGF0YS5pby92Mw=="
  access-key: "cmVnaXN0cmF0aW9uVG9rZW4="
  secret-key: "M0Q4Q0Y1NzIwNDlDREIwODFGMzk6MTU0NjIxNDQwMDAwMDpjYnhGdnhGU0ZoanB6QmJjbVhjbzBHUkpr"

---

# cluster-register Job
apiVersion: batch/v1
kind: Job
metadata:
  name: cluster-register
  namespace: maya-system
spec:
  template:
    spec:
      serviceAccountName: maya-io
      restartPolicy: Never
      containers:
      - name: cluster-register
        env: 
        image: mayadataio/cluster-register:v1.11.22
        volumeMounts:
        - name: maya-credentials
          mountPath: /maya-credentials
          readOnly: true
        - name: cortex-agent-volume
          mountPath: /etc/prometheus
          readOnly: true
      volumes:
      - name: maya-credentials
        secret:
          secretName: maya-credentials-842dac64
      - name: cortex-agent-volume
        configMap:
          name: cortex-agent-config

---


# status-agent deployment
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: status-agent
  labels:
    name: status-agent
  namespace: maya-system
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/maya-credentials-842dac64-secret: 7d973d2969aeed4fab963fc66b0e7fee7d605d438673c5c8106a7fe1dbe8feca
      labels:
        name: status-agent
    spec:
      serviceAccountName: maya-io
      containers:
      - name: status-agent
        env: 
        image: mayadataio/status-agent:v1.11.34
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            memory: "50Mi"
            cpu: "50m"
        volumeMounts:
        - name: maya-credentials
          mountPath: /maya-credentials
          readOnly: true
      volumes:
      - name: maya-credentials
        secret:
          secretName: maya-credentials-842dac64

---

# upgrade-controller deployment
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: upgrade-controller
  namespace: maya-system
  labels:
    name: upgrade-controller
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/maya-credentials-842dac64-secret: 7d973d2969aeed4fab963fc66b0e7fee7d605d438673c5c8106a7fe1dbe8feca
      labels:
        name: upgrade-controller
    spec:
      serviceAccountName: maya-io
      containers:
      - name: upgrade-controller
        env: 
        - name: ENABLE_DEBUG_LOG
          value: "false"
        - name: RUN_INTERVAL
          value: "300"
        image: mayadataio/upgrade-controller:v1.11.34
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: maya-credentials
          mountPath: /maya-credentials
          readOnly: true
      volumes:
      - name: maya-credentials
        secret:
          secretName: maya-credentials-842dac64

---

apiVersion: apps/v1
# Kubernetes version 1.8.x should use apps/v1beta2
# Kubernetes versions before 1.8.0 should use apps/v1beta1 or extensions/v1beta1
kind: Deployment
metadata:
  name: kube-state-metrics
  namespace: maya-system
spec:
  selector:
    matchLabels:
      k8s-app: kube-state-metrics
  replicas: 1
  template:
    metadata:
      labels:
        k8s-app: kube-state-metrics
    spec:
      serviceAccountName: maya-io
      containers:
      - name: kube-state-metrics
        image: quay.io/coreos/kube-state-metrics:v1.5.0
        ports:
        - name: http-metrics
          containerPort: 80
        - name: telemetry
          containerPort: 81
        readinessProbe:
          httpGet:
            path: /healthz
            port: 80
          initialDelaySeconds: 5
          timeoutSeconds: 5
        command:
        - "/kube-state-metrics"
        - --namespace
        - "openebs,maya-system"
        - --metric-whitelist
        - "kube_pod_container_status_waiting_reason,kube_pod_container_status_running,kube_node_status_condition"
        - --collectors
        - "pods,nodes"
      - name: addon-resizer
        image: k8s.gcr.io/addon-resizer:1.8.3
        resources:
          limits:
            cpu: 150m
            memory: 50Mi
          requests:
            cpu: 100m
            memory: 50Mi
        env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: MY_POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        command:
          - /pod_nanny
          - --container=kube-state-metrics
          - --cpu=120m
          - --extra-cpu=1m
          - --memory=100Mi
          - --extra-memory=2Mi
          - --threshold=5
          - --deployment=kube-state-metrics

---

apiVersion: v1
kind: Service
metadata:
  name: kube-state-metrics
  namespace: maya-system
  labels:
    k8s-app: kube-state-metrics
  annotations:
    prometheus.io/scrape: 'true'
spec:
  ports:
  - name: http-metrics
    port: 80
    targetPort: http-metrics
    protocol: TCP
  - name: telemetry
    port: 81
    targetPort: telemetry
    protocol: TCP
  selector:
    k8s-app: kube-state-metrics


---

# cortex-agent-config configmap
kind: ConfigMap
metadata:
  name: cortex-agent-config
  namespace: maya-system
  labels:
    version: v1.11.5
apiVersion: v1
data:
  prometheus.yml: |-
    global:
      external_labels:
        slave: skyhouse-l5l2m
      scrape_interval: 1m
      evaluation_interval: 1m
    remote_write:
    - url: 'https://director.mayadata.io/maya-cortex-push/api/prom/push'
      basic_auth:
        username: 53EC7BB21A39963BDF63
        password: T5bc6jwY9F6uuCRgANkEku8Hqpr4DVnXirkuafYC
      proxy_url: 
    remote_read:
    - url: 'https://director.mayadata.io/maya-cortex-pull/api/prom/read'
      basic_auth:
        username: 53EC7BB21A39963BDF63
        password: T5bc6jwY9F6uuCRgANkEku8Hqpr4DVnXirkuafYC
      proxy_url: 
    scrape_configs:
    - job_name: 'cluster_uuid_skyhouse-l5l2m_cortex-agent-retriever'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_name]
        regex: cortex-agent-retriever
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
    - job_name: 'cluster_uuid_skyhouse-l5l2m_openebs-volumes'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_monitoring]
        regex: volume_exporter_prometheus
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_persistent_volume]
        action: replace
        target_label: openebs_pv
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_persistent_volume_claim]
        action: replace
        target_label: openebs_pvc
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: drop
        regex: '(.*)9501'
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: drop
        regex: '(.*)3260'
    - job_name: 'cluster_uuid_skyhouse-l5l2m_kube-state-metrics'
      scheme: http
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace]
        regex: maya-system
        action: keep
      - source_labels: [__meta_kubernetes_service_name]
        regex: kube-state-metrics
        action: keep
      - source_labels: [__meta_kubernetes_service_port_name]
        regex: 'http-metrics'
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_openebs-pools'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_openebs_io_monitoring]
        regex: pool_exporter_prometheus
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_storage_pool_claim]
        action: replace
        target_label: storage_pool_claim
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_cstor_pool]
        action: replace
        target_label: cstor_pool
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: ${1}:${2}
        target_label: __address__
    - job_name: 'cluster_uuid_skyhouse-l5l2m_minio-app'
      metrics_path: /minio/prometheus/metrics
      static_configs:
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: minio
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_cockroachdb-app'
      metrics_path: '/_status/vars'
      scheme: 'http'
      tls_config:
        insecure_skip_verify: true
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: cockroachdb
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_postgresql-app'
      metrics_path: '/metrics'
      static_configs:
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: postgres-exporter
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_redis-app'
      metrics_path: '/metrics'
      static_configs:
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: redis
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_elasticsearch-app'
      metrics_path: '/metrics'
      static_configs:
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: elasticsearch-exporter
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
    - job_name: 'cluster_uuid_skyhouse-l5l2m_mysql-app'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: mysql-exporter
        action: keep
    - job_name: 'cluster_uuid_skyhouse-l5l2m_chaos-metrics'
      scrape_interval: 5s
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: chaos-exporter
        action: keep

---

# cortex-agent-deployment
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: cortex-agent
  namespace: maya-system
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/cortex-agent-config: 22143ac18bdfad52ec2f5e8456fa591ef54ffee3fd5a3493d9d14a7ffba9d279
      labels:
        name: cortex-agent-retriever
    spec:
      serviceAccountName: maya-io
      initContainers:
      - name: init-agent
        image: mayadataio/maya-init:v1.11.1
        command:
        - sh
        - "-c"
        - |
          set -ex
          export MAYA=$(kubectl get ClusterRoleBinding | grep -w maya-io | awk '{print $1}')
          echo $MAYA
          until [ ! -z "$MAYA" ]
          do
             echo "wating for ClusterRoleBinding"
             sleep 1;
          done
      containers:
        - name: retrieval
          image: prom/prometheus:v1.7.1
          args:
            - "-config.file=/etc/prometheus/prometheus.yml"
            - "-web.listen-address=:80"
          ports:
            - containerPort: 80
          volumeMounts:
            - name: cortex-agent-volume
              mountPath: /etc/prometheus
      volumes:
        - name: cortex-agent-volume
          configMap:
            name: cortex-agent-config

---

# cortex-agent-service
apiVersion: v1
kind: Service
metadata:
  name: cortex-agent-service
  namespace: maya-system
spec:
  type: ClusterIP
  ports:
    - port: 80
  selector:
    name: cortex-agent-retriever

---

# fluentd-forwarder configmap
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-forwarder
  namespace: maya-system 
  labels:
    k8s-app: fluentd-forwarder
    version: v1.11.6
data:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>

  containers.input.conf: |-
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/es-containers.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      tag raw.kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

     # Fetching kubelet logs
    <source>
      @type systemd
      tag kubelet
      path /var/log/journal
      matches [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      read_from_head true
      <storage>
        @type local
        persistent true
        path /var/log/journald_pos.json
      </storage>
      <entry>
        fields_strip_underscores true
        fields_lowercase true
      </entry>
    </source>

    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>

  output.conf: |-
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>

    # Routing kubelet logs
    <match kubelet>
      @type relabel
      @label @MO_LOGS
    </match>

    # Excluding logs of fluentd
    <match kubernetes.var.log.containers.**fluentd**.log>
      @type null
    </match>
    
    # Excluding logs of openebs-monitor-plugin pod
    <match kubernetes.var.log.containers.**openebs-monitor-plugin**.log>
      @type null
    </match>
    
    # Routing logs of maya-system namespace
    <match kubernetes.var.log.containers.**_maya-system_**.log>
      @type relabel
      @label @MO_LOGS
    </match>

    # Routing logs of litmus namespace
    <match kubernetes.var.log.containers.**_litmus_**.log>
      @type relabel
      @label @MO_LOGS
    </match>

    # Catching pods with label and routing logs
    <match kubernetes.**>
      @type rewrite_tag_filter
      <rule>
        key $.kubernetes.labels.openebs_io/persistent-volume
        pattern ^(.+)$
        tag openebs
      </rule>
      <rule>
        key $.kubernetes.labels.app
        pattern ^cstor-pool$
        tag openebs
      </rule>
      <rule>
        key $.kubernetes.labels.name
        pattern ^(maya-apiserver|openebs-ndm|openebs-provisioner|openebs-snapshot-operator)$
        tag openebs
      </rule>
    </match>
   
    # Tag the openebs error logs
    <match openebs>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern /(failed to get any path for iscsi disk|connection refused|cannot make connection|no portals found)/i
        tag openebs.error.iscsi-disk-path-failure
      </rule>
      <rule>
        key log
        pattern /(I\/O error|EXT4-fs error|remounting filesystem read-only|previous I\/O error to superblock detected)/i
        tag openebs.error.volume-went-read-only
      </rule>
      <rule>
        key log
        pattern /(healthy count|degraded count|non-quorum-replica count)/i
        tag openebs.error.cvr-health-status
      </rule>
      <rule>
        key log
        pattern /failed to execute runtask/i
        tag openebs.error.runtask-execution-failure
      </rule>
      # Jiva
      <rule>
        key log
        pattern /(connection reset by peer|error reading from wire|exiting rpc reader|Closing rpc server)/i
        tag openebs.error.data-connection-failure
      </rule>
      <rule>
        key log
        pattern /(expected [0-9]+ no of replica pod|failed to execute runtask)/i
        tag openebs.error.jiva-volume-provision-failure
      </rule>
      <rule>
        key log
        pattern /replicas are less/i
        tag openebs.error.replication-factor-failure
      </rule>
      <rule>
        key log
        pattern /replica in rebuilding state/i
        tag openebs.error.replica-rebuilding
      </rule>
      <rule>
        key log
        pattern /ReadOnly/i
        tag openebs.error.read-only-jiva
      </rule>
      <rule>
        key log
        pattern /Incomplete write expected/i
        tag openebs.error.multiwriter-error-jiva
      </rule>
      <rule>
        key log
        pattern /Failed to add replica/i
        tag openebs.error.replica-add-failure-jiva
      </rule>
      <rule>
        key log
        pattern /Fail to get size of file/i
        tag openebs.error.get-file-size-failure-jiva
      </rule>
      # NDM
      <rule>
        key log
        pattern /Disk CRD is not available yet/i
        tag openebs.error.disk-crd-not-installed-in-cluster
      </rule>
      <rule>
        key log
        pattern /BlockDevice CRD is not available yet/i
        tag openebs.error.blockdevice-not-installed-in-cluster
      </rule>
      <rule>
        key log
        pattern /could not get device mount attributes/i
        tag openebs.error.device-getting-mount-information-failure
      </rule>
      <rule>
        key log
        pattern /device type is not supported yet/i
        tag openebs.error.device-not-supported
      </rule>
      <rule>
        key log
        pattern /Unable to get device info/i
        tag openebs.error.seachest-probe-failure
      </rule>
      <rule>
        key log
        pattern /DetectScsiTypeError:no such file or directory/i
        tag openebs.error.smartprobe-failure
      </rule>
      # cStor
      <rule>
        key log
        pattern /(Unable to clear label|failed to check state|Unable to clear labels from the disks|Unable to create pool|contains a ext4 filesystem|pool creation failure)/i
        tag openebs.error.cstor-pool-provision-failure
      </rule>
      <rule>
        key log
        pattern /(not enough pools available to create replicas|failed to provision volume|failed to create volume)/i
        tag openebs.error.cstor-volume-provision-failure
      </rule>
      <rule>
        key log
        pattern ^(.+)$ 
        tag openebs.log
      </rule>
    </match>

    <match openebs**>
      @type relabel
      @label @MO_LOGS
    </match>

    <match **>
      @type null
    </match>

    # Adding field for cluster_id
    <label @MO_LOGS>
      <filter **>
        @type elasticsearch_genid  # elasticsearch_genid filter generates a unique _hash key for each record to prevent duplicates
        hash_id_key _hash  # storing generated hash id key (default is _hash)
      </filter>

      <filter openebs.error.**>
        @type record_transformer
        <record>
          openebs_errors ${tag_parts[2]}
        </record>
      </filter>

      <filter **>
        @type record_transformer
        <record>
          cluster_id skyhouse-l5l2m
        </record>
      </filter>

      <match **>
        @type forward
        compress gzip
        require_ack_response true
        ack_response_timeout 30
        recover_wait 10s
        heartbeat_interval 1s
        phi_threshold 16
        send_timeout 10s
        hard_timeout 10s
        expire_dns_cache 15
        heartbeat_type tcp
        <buffer>
          flush_thread_count 8
          flush_interval 5s
          retry_forever 
          retry_max_interval 15
          chunk_limit_size 2M
          queue_limit_length 32
        </buffer>
        <server>
          name fluentd-aggregator
          host fluentd-aggregator
          port 24224
          weight 60
        </server>
      </match>
    </label>

---

# fluentd-aggregator configmap
kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-aggregator
  namespace: maya-system
  labels:
    k8s-app: fluentd-aggregator
    version: v1.11.5
data:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
    </system>
  output.conf: |-
    <source>
      @type forward
      port 24224
    </source>
    <match **>
      @id elasticsearch
      @type elasticsearch
      id_key _hash  # specify same key name which is specified in hash_id_key
      remove_keys _hash  # Elasticsearch doesn't like keys that start with _ so remove it  
      logstash_format true
      include_timestamp true
      unrecoverable_error_types ["out_of_memory_error"]
      # this indicates that the plugin should reset connection on any error
      reconnect_on_error true
      # logstash_prefix value gets added as prefix to index
      logstash_prefix 53EC7BB21A39963BDF63-skyhouse-l5l2m
      # Important (required to connect with elasticsearch with https request)
      scheme https
      ssl_version TLSv1_2
      include_tag_key true
      hosts https://director.mayadata.io/elasticsearch/
      # Elasticsearch authentication 
      user 53EC7BB21A39963BDF63
      password T5bc6jwY9F6uuCRgANkEku8Hqpr4DVnXirkuafYC
      <buffer>
        @type file
        path /var/log/fluentd-buffers/kubernetes.system.buffer.aggregator
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 3
        flush_interval 5s
        retry_forever
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 32
        overflow_action block
      </buffer>
    </match>

---

# fluentd-aggregator deployment
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: fluentd-aggregator
  namespace: maya-system
  labels:
    k8s-app: fluentd-aggregator
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-aggregator
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/fluentd-aggregator: bb2040ac0231e386c4548a5410508303111f09e98484c3c0fc0124b1ef86a373
      labels:
        k8s-app: fluentd-aggregator
    spec:
      initContainers:
      - name: init-agent
        image: mayadataio/maya-init:v1.11.1
        command:
        - sh
        - "-c"
        - |
          set -ex
          export MAYA=$(kubectl get ClusterRoleBinding | grep -w maya-io | awk '{print $1}')
          echo $MAYA
          until [ ! -z "$MAYA" ]
          do
             echo "wating for ClusterRoleBinding"
             sleep 1;
          done
      containers:
      - name: fluentd-aggregator
        env: 
        image: mayadataio/maya-fluentd:v1.11.9
        imagePullPolicy: IfNotPresent
        ports:
        - name: fwd-input
          containerPort: 24224
          protocol: TCP
        volumeMounts:
        - name: config-volume
          mountPath: /etc/fluent/config.d
      volumes:
      - name: config-volume
        configMap:
          name: "fluentd-aggregator"
      # Give the aggregator ample time to flush it's logs
      terminationGracePeriodSeconds: 20
      serviceAccountName: maya-io
      
---

# fluentd-aggregator service
apiVersion: v1
kind: Service
metadata:
  name: fluentd-aggregator
  namespace: maya-system
  labels:
    k8s-app: fluentd-aggregator
spec:
  ports:
  - port: 24224
    protocol: TCP
    targetPort: 24224
  selector:
    k8s-app: fluentd-aggregator

---

# fluentd-forwarder daemonset
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-forwarder
  namespace: maya-system
  labels:
    k8s-app: fluentd-forwarder
    kubernetes.io/cluster-service: "true"
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-forwarder
  template:
    metadata:
      annotations:
        checksum/fluentd-forwarder: d4a033d52f5a3d913b25a99ed0297dd9b89363c62fd6ae87c2a2a23f71b7c27e
      labels:
        k8s-app: fluentd-forwarder
        kubernetes.io/cluster-service: "true"
    spec:
      serviceAccountName: maya-io
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      initContainers:
      - name: init-agent
        image: mayadataio/maya-init:v1.11.1
        command:
        - sh
        - "-c"
        - |
          set -ex
          export MAYA=$(kubectl get ClusterRoleBinding | grep -w maya-io | awk '{print $1}')
          echo $MAYA
          until [ ! -z "$MAYA" ]
          do
             echo "wating for ClusterRoleBinding"
             sleep 1;
          done
      containers:
      - name: fluentd-forwarder
        image: mayadataio/maya-fluentd:v1.11.11
        securityContext:
          privileged: true
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config-volume
          mountPath: /etc/fluent/config.d
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      terminationGracePeriodSeconds: 20
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config-volume
        configMap:
          name: fluentd-forwarder

---

# maya-scope-deployment
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: weave-scope-app
  labels:
    name: weave-scope-app
    app: weave-scope
    maya-cloud-component: scope
    maya-scope-component: app
  namespace: maya-system
spec:
  replicas: 1
  revisionHistoryLimit: 2
  template:
    metadata:
      labels:
        name: weave-scope-app
        app: weave-scope
        maya-cloud-component: scope
        maya-scope-component: app
    spec:
      serviceAccountName: maya-io
      containers:
        - name: app
          args:
            - '--no-probe'
          image: openebs/scope:v1.11.1749
          imagePullPolicy: Always
          ports:
            - containerPort: 4040
              protocol: TCP

---

apiVersion: v1
kind: Service
metadata:
  name: weave-scope-app
  labels:
    name: weave-scope-app
    app: weave-scope
    maya-cloud-component: scope
    maya-scope-component: app
  namespace: maya-system
spec:
  ports:
    - port: 80
      protocol: TCP
      targetPort: 4040
  selector:
    name: weave-scope-app
    app: weave-scope
    maya-cloud-component: scope
    maya-scope-component: app

---

apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: weave-scope-agent
  labels:
    name: weave-scope-agent
    app: weave-scope
    maya-cloud-component: scope
    maya-scope-component: agent
  namespace: maya-system
spec:
  template:
    metadata:
      labels:
        name: weave-scope-agent
        app: weave-scope
        maya-cloud-component: scope
        maya-scope-component: agent
    spec:
      containers:
        - name: scope-agent
          args:
            - '--no-app'
            - '--probe.docker.bridge=docker0'
            - '--probe.docker=true'
            - '--probe.kubernetes=true'
            - 'weave-scope-app:80'
          env: []
          image: openebs/scope:v1.11.1749
          imagePullPolicy: Always
          securityContext:
            privileged: true
          volumeMounts:
            - name: docker-socket
              mountPath: /var/run/docker.sock
            - name: sys-kernel-debug
              mountPath: /sys/kernel/debug
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      hostPID: true
      serviceAccountName: maya-io
      tolerations:
        - effect: NoSchedule
          operator: Exists
      volumes:
        - name: docker-socket
          hostPath:
            path: /var/run/docker.sock
        - name: sys-kernel-debug
          hostPath:
            path: /sys/kernel/debug
  updateStrategy:
    type: RollingUpdate

---

